{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTS6eywErZD1"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be4_q_pmwXNi",
    "outputId": "dbe76b40-473e-436c-c44f-523c336e140e"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ogpL9Zcv5Di",
    "outputId": "8f8204fd-3e51-4cac-ccd7-250240c706a5"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5m_E4zbrfTI",
    "outputId": "a849bd24-44e9-49be-f830-0d078b2c8b71"
   },
   "outputs": [],
   "source": [
    "!pip install -qU transformers datasets peft wandb vllm accelerate bitsandbytes wandb faker evaluate sacrebleu rouge_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdGuDEzTpoEb",
    "outputId": "eef764dc-e691-4e53-f625-70c452d89ab6"
   },
   "outputs": [],
   "source": [
    "# !pip install -qU torch==\"2.4.1+cu121\" torchvision==\"0.19.1+cu121\" torchaudio==\"2.4.1+cu121\" --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -qU packaging ninja\n",
    "!pip install -qU flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwcErgaRpr95",
    "outputId": "9e43cd0c-a050-4b1b-c7fb-65f4787ff0b7"
   },
   "outputs": [],
   "source": [
    "import flash_attn\n",
    "print(flash_attn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uj8oNqDcrsRg"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ikja2_JrvHG"
   },
   "source": [
    "## Evaluate LLM Model on Arabic Authorship Styling Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhcoC4Amrvkt"
   },
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "torch_dtype = \"auto\" # None, torch.float16\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IipHg1pXrxt9",
    "outputId": "0e20c64c-c0d4-4ee7-c012-00cac2773be6"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype = torch_dtype\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz-0aqu-xOkN",
    "outputId": "2d381328-b154-4aa4-8d4e-e0e3bdf38950"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27goJecWbpcd"
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geEzYR9nbxf2",
    "outputId": "0274c2b4-869f-4400-fb44-7ed846df08c5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "data_dir = \"/gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1\"\n",
    "train_path = os.path.join(data_dir, \"AuthorshipStyleTransferTrain.xlsx\")\n",
    "validation_path = os.path.join(data_dir, \"AuthorshipStyleTransferVal.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "VLEPk_V1r69a",
    "outputId": "31c9f2ba-f2b8-49ea-884f-415ec860c2c5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(train_path)\n",
    "test_df = pd.read_excel(validation_path)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYbKX9SXfLzp",
    "outputId": "6ca02b8b-ebff-4f8c-d210-150fd8590e27"
   },
   "outputs": [],
   "source": [
    "train_word_counts = df['text_in_author_style'].str.split().str.len()\n",
    "val_word_counts = test_df['text_in_author_style'].str.split().str.len()\n",
    "\n",
    "max_train_word_counts, min_train_word_counts = train_word_counts.max(), train_word_counts.min()\n",
    "max_val_word_counts, min_val_word_counts = val_word_counts.max(), val_word_counts.min()\n",
    "\n",
    "print(f\"{max_train_word_counts=}\\n{min_train_word_counts=}\\n{max_val_word_counts=}\\n{min_val_word_counts=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152,
     "referenced_widgets": [
      "e8c7543fdf6345f4bfd1088c827dbffc",
      "b84c34772a8247ce9ec7f0d07854f186",
      "d9c28ca7d5b14b76b6a7a35d3cd76a65",
      "d187ae3b428f4130a11ea157183b5b98",
      "1fac024aec2c41d1810808424aaa9fc3",
      "e9a1149023b34161837f6256e29c87bd",
      "32bcb568e8dc4c4f9158e218ec6e99e9",
      "61f74c31f9414c2d97e331cc3bc9c395",
      "1dc7587750974e8e8f9595868ad783df",
      "7afcd5353ac24a07b973154a93a0c6aa",
      "7b427d66ca6f4f8b88ef507d89993960",
      "7e77fb1f187c4b0b906d07bcc7ae4487",
      "192a977575b1422f911dd1e1e387bdaa",
      "69d1dfa44d10419f84bbf6215e3b6b6d",
      "21cdcfb3187b445193835c3828cf8d21",
      "40b4746daf004b4ca3faac5fda98c66e",
      "c24e6c23780242399239fadf3e13d4f8",
      "60072b5e25324f27a29b955ce35c942b",
      "95372ecbe05a4662839a5aa8785c64c7",
      "fb862ae335b74fcd823e3b84066adb03",
      "553b3334a1124074a44e23172011a20d",
      "4d283dfc38874eb5a071d0956aba6d10"
     ]
    },
    "id": "jVw8lEUevBKF",
    "outputId": "0b96ff93-d20c-4cdf-8ff0-8fd915c8fdeb"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for batching\n",
    "def count_tokens_batch(texts, tokenizer, batch_size=512):\n",
    "    token_counts = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_encodings = tokenizer(batch_texts, add_special_tokens=False, truncation=False)\n",
    "        batch_counts = [len(ids) for ids in batch_encodings['input_ids']]\n",
    "        token_counts.extend(batch_counts)\n",
    "    return np.array(token_counts)\n",
    "\n",
    "# For training set\n",
    "train_texts = df['text_in_author_style'].tolist()\n",
    "train_token_counts = count_tokens_batch(train_texts, tokenizer)\n",
    "\n",
    "# For validation/test set\n",
    "val_texts = test_df['text_in_author_style'].tolist()\n",
    "val_token_counts = count_tokens_batch(val_texts, tokenizer)\n",
    "\n",
    "# Show stats\n",
    "print(f\"max_train_token_counts={train_token_counts.max()}\")\n",
    "print(f\"min_train_token_counts={train_token_counts.min()}\")\n",
    "print(f\"max_val_token_counts={val_token_counts.max()}\")\n",
    "print(f\"min_val_token_counts={val_token_counts.min()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJSwo8kcq7Oh"
   },
   "outputs": [],
   "source": [
    "max_new_tokens = int(max(train_token_counts.max(), val_token_counts.max()) + 500)\n",
    "min_new_tokens = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlyQMvE6dsnW",
    "outputId": "e3f4ce6d-707c-4b23-c9ac-555c7802b89a"
   },
   "outputs": [],
   "source": [
    "src_text = test_df.iloc[0]['text_in_msa']\n",
    "transfered_text = test_df.iloc[0]['text_in_author_style']\n",
    "author_name = test_df.iloc[0]['author']\n",
    "\n",
    "print(f\"Author: {author_name}\")\n",
    "print(\"**\"*10)\n",
    "print(f\"Source Text: {src_text}\")\n",
    "print(\"**\"*10)\n",
    "print(f\"Transfered Text: {transfered_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZCnOWNEsAuu"
   },
   "outputs": [],
   "source": [
    "system_message = \"\\n\".join([\n",
    "    \"You are an advanced NLP experts specializing in text style transfer and semantic preservation.\",\n",
    "    \"Your role is to transform input text into the unique writing style of a specified author, ensuring the transformed output retains the original meaning, nuances, and intent.\",\n",
    "    \"Always follow instructions carefully, preserve the semantics of the source text, and ensure the generated output accurately reflects the distinctive style and tone of the given author.\",\n",
    "    \"Generate the ouptut in the same text language.\",\n",
    "    \"Do not generate any introduction or conclusion.\"\n",
    "])\n",
    "\n",
    "user_message = \"\\n\".join([\n",
    "            \"<task> Transform the following source text into the writing style of the specified author.\",\n",
    "            f\"<author> {author_name.strip()}\",\n",
    "            f\"<source> {src_text.strip()}\",\n",
    "            \"<output>\"\n",
    "        ])\n",
    "\n",
    "llm_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message,\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LrT-zmytvkR",
    "outputId": "8f9cedb5-1787-4457-8736-8b2edbb94a6c"
   },
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    llm_messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    min_new_tokens=min_new_tokens,\n",
    "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
    ")\n",
    "\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2sBk9mfuMA7",
    "outputId": "cdf5428b-6bf6-4afd-e888-32da6fa22cd6"
   },
   "outputs": [],
   "source": [
    "print('LLM Transfered Text:\\n')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqIRbR8Ivnks"
   },
   "source": [
    "## Finetuning Phase\n",
    "\n",
    "Format Finetuning Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyDqBVS9xGbQ"
   },
   "source": [
    "Reduce training dataset to 10% of its original size (while preserving the class `author` distribution), and then split 10% of that reduced data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 795
    },
    "id": "tFw07-7_wwpF",
    "outputId": "84f0517b-5b3e-47e5-c168-31395cd11366"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Reduce df to n% of original size, stratified by 'author'\n",
    "df_reduced = df.groupby('author', group_keys=False).apply(lambda x: x.sample(frac=0.2, random_state=42))\n",
    "df_reduced = df_reduced.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "# 2. Split df_10 into train (90%) and validation (10%), stratified\n",
    "train_df, val_df = train_test_split(\n",
    "    df_reduced,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df_reduced['author']\n",
    ")\n",
    "\n",
    "# 3. Calculate normalized value counts (proportion) for each split\n",
    "original_dist = df['author'].value_counts(normalize=True)\n",
    "reduced_dist = df_reduced['author'].value_counts(normalize=True)\n",
    "train_dist = train_df['author'].value_counts(normalize=True)\n",
    "val_dist = val_df['author'].value_counts(normalize=True)\n",
    "test_dist = test_df['author'].value_counts(normalize=True)\n",
    "\n",
    "# 4. Combine into a single DataFrame for display\n",
    "distribution_table = pd.DataFrame({\n",
    "    'Original': original_dist,\n",
    "    'Reduced10%': reduced_dist,\n",
    "    'Train': train_dist,\n",
    "    'Validation': val_dist,\n",
    "    'Test': test_dist,\n",
    "}).fillna(0)\n",
    "\n",
    "# 5. Display as a table in Colab/Notebook\n",
    "distribution_table.style.format(\"{:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TU6CSM5xUhb"
   },
   "source": [
    "here if want to train on the full training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGwgAjv8wExi"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Assuming df is your DataFrame\n",
    "# train_df, val_df = train_test_split(\n",
    "#     df,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=df['author']\n",
    "# )\n",
    "\n",
    "# # Calculate normalized value counts (proportion) for each split\n",
    "# original_dist = df['author'].value_counts(normalize=True)\n",
    "# train_dist = train_df['author'].value_counts(normalize=True)\n",
    "# val_dist = val_df['author'].value_counts(normalize=True)\n",
    "# test_dist = test_df['author'].value_counts(normalize=True)\n",
    "\n",
    "# # Combine into a single DataFrame for display\n",
    "# distribution_table = pd.DataFrame({\n",
    "#     'Original': original_dist,\n",
    "#     'Train': train_dist,\n",
    "#     'Validation': val_dist,\n",
    "#     'Test': test_dist,\n",
    "# }).fillna(0)  # In case some authors don't appear in a split\n",
    "\n",
    "# # Display as a table in Colab\n",
    "# distribution_table.style.format(\"{:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thf6vN2BAlWw"
   },
   "source": [
    "Install LLaMA-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQOm_d5MAkt4"
   },
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "!cd LLaMA-Factory && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDWs5C8w9x3J"
   },
   "source": [
    "Login to HuggingFace <img src=\"https://huggingface.co/front/assets/huggingface_logo.svg\" alt=\"Hugging Face\" width=\"40\"/> , W&B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5V-EhE6JyjnM",
    "outputId": "016cffd2-477a-47c2-a982-c8bb2e00ee99"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import wandb\n",
    "\n",
    "wandb.login(key=userdata.get('wandb_colab'))\n",
    "hf_token = userdata.get('HF_API_KEY')\n",
    "!huggingface-cli login --token {hf_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-TbGE6Fj1zp"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_authors = sorted(train_df['author'].unique())\n",
    "\n",
    "system_message = \"\\n\".join([\n",
    "    \"You are an advanced NLP experts specializing in text style transfer and semantic preservation.\",\n",
    "    \"Your role is to transform input text into the unique writing style of a specified author, ensuring the transformed output retains the original meaning, nuances, and intent.\",\n",
    "    \"Always follow instructions carefully, preserve the semantics of the source text, and ensure the generated output accurately reflects the distinctive style and tone of the given author.\",\n",
    "    \"Generate the ouptut in the same text language.\",\n",
    "    \"Do not generate any introduction or conclusion.\"\n",
    "])\n",
    "\n",
    "PROMPT_TEMPLATES = [\n",
    "    \"<task> Emulate the style of <author> {author}: “{source}” →\",\n",
    "    \"<task> Rewrite the following in {author}'s voice:\\n“{source}”\\nResult:\",\n",
    "    \"As if written by {author}, transform:\\n\\\"{source}\\\"\\n--\",\n",
    "    \"Write in {author}'s unique style. Source:\\n{source}\\nOutput:\"\n",
    "]\n",
    "\n",
    "# Define a small pool of classification prompts\n",
    "CLASSIFICATION_TEMPLATES = [\n",
    "    \"<task> Identify the author of this text:\\n“{source}”\\nAnswer:\",\n",
    "    \"Given the following Arabic sentence, choose the author:\\n\\\"{source}\\\"\\nAuthor:\",\n",
    "    \"Text:\\n{source}\\nWhich author wrote this? →\"\n",
    "]\n",
    "\n",
    "\n",
    "def format_chat(example):\n",
    "    prompt = \"\\n\".join([\n",
    "            \"<task> Transform the following source text into the writing style of the specified author.\",\n",
    "            f\"<author> {example['author'].strip()}\",\n",
    "            f\"<source> {example['text_in_msa'].strip()}\",\n",
    "            \"<output>\"\n",
    "        ])\n",
    "\n",
    "\n",
    "    message = {\n",
    "        \"system\": system_message,\n",
    "        \"instruction\": prompt,\n",
    "        \"input\": \"\",\n",
    "        \"output\": example['text_in_author_style'].strip(),\n",
    "        \"history\": []\n",
    "    }\n",
    "    return message\n",
    "\n",
    "\n",
    "def format_style(example):\n",
    "    \"\"\"Create one style-transfer example with prompt variation.\"\"\"\n",
    "    tmpl = random.choice(PROMPT_TEMPLATES)\n",
    "    instruction = tmpl.format(\n",
    "        author=example['author'].strip(),\n",
    "        source=example['text_in_msa'].strip()\n",
    "    )\n",
    "    return {\n",
    "        \"system\": system_message,\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": \"\",\n",
    "        \"output\": example['text_in_author_style'].strip(),\n",
    "        \"history\": []\n",
    "    }\n",
    "\n",
    "def format_classification(example, all_authors, k=3):\n",
    "    \"\"\"Classification example with k random distractors + correct author.\"\"\"\n",
    "    # pick k random negative authors\n",
    "    negatives = random.sample([a for a in all_authors if a != example['author']], k)\n",
    "    choices = negatives + [example['author']]\n",
    "    random.shuffle(choices)\n",
    "\n",
    "    tmpl = random.choice(CLASSIFICATION_TEMPLATES)\n",
    "    instruction = tmpl.format(source=example['text_in_author_style'].strip())\n",
    "    # append the multiple-choice list\n",
    "    instruction += \" [\" + \" | \".join(choices) + \"]\"\n",
    "\n",
    "    return {\n",
    "        \"system\": system_message,\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": \"\",\n",
    "        \"output\": example['author'].strip(),\n",
    "        \"history\": []\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# 4) Build a mixed multi-task formatter\n",
    "def format_multi(example, p_style=0.8):\n",
    "    if random.random() < p_style:\n",
    "        return format_style(example)\n",
    "    else:\n",
    "        return format_classification(example, all_authors, k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "ce9e406574ef4ac88cb52d207f4f38e5",
      "3bdf5602c3c448d489fcb2b9e964278d",
      "5f5f130179054ccd8c0971fe0c4ccf21",
      "e2c28a0a494940e7931e33556bd85ad3",
      "625e31c6fd074b8bb3e55b29503bc784",
      "657506d1799e437c885a4a8420f3573b",
      "82408f3e12fe48de8ac882c6edb7aae2",
      "23ce5043154c4af5a6a9102bf476e4ba",
      "49f2ca1f719c432b98d55acfdd0c8502",
      "03041a6825bb4bfb921a4c853c03ed64",
      "5bf8a703640649029f7a9349c0a456fb",
      "1e923f93705e4d98ae2f743db3228409",
      "8640e77d0f304f089f13c9d651e38f68",
      "85d6c0a1db154bd99f12dcee540cdd35",
      "43689df49f6a4de0a3264be460ca102a",
      "6caafade35644e0993d7de1c609d58a0",
      "4eac538908554978b24ef03ade0bbb9f",
      "1e62a90af4ab4155a5766a3e073edc71",
      "50b4d877c55d4506b9d45084ca459067",
      "ffad0664c3a340a59a4eec2385361605",
      "3a337862d48d4d18923189342dbfa724",
      "c24e21cdfc274ac79e0666c08ce36f98",
      "a0e1bcc9f26d4a658e9b759898401e1d",
      "8eae1c26c173488ea4eee86ec694e76a",
      "3bd9d0bbfc1c4038a14730b05fec755c",
      "1fbc02059b3f43918ca1f49d3ff22b5a",
      "2ccb2a0c4bee409db646b2252b091f8d",
      "b94cc3628be84ac4a6475fca0cfd65d1",
      "9eea68c350de4d3a9949670e4f93fefd",
      "9360c990d2d8410e9324736298bf835a",
      "6661a836a06f4029a09a9dd2e27396d9",
      "b0ca7e6b70734a69934c4cc62a49a57f",
      "c3dca4902301494f836f85939ab2b9c0"
     ]
    },
    "id": "Dojsuo4xGfgF",
    "outputId": "81bfb95e-bce0-4dfb-879b-199836c17591"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# train_ds = train_df.progress_apply(format_chat, axis=1)\n",
    "# val_ds = val_df.progress_apply(format_chat, axis=1)\n",
    "# test_ds = test_df.progress_apply(format_chat, axis=1)\n",
    "\n",
    "train_ds = train_df.progress_apply(format_multi, axis=1)\n",
    "val_ds   = val_df.progress_apply(lambda ex: format_style(ex), axis=1)   # eval only style\n",
    "test_ds  = test_df.progress_apply(lambda ex: format_style(ex), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9egtU9ODLrB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "output_dir = os.path.join(data_dir, \"datasets\", \"llamafactory-finetune-data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# convert pandas Series to list\n",
    "train_list = list(train_ds)\n",
    "val_list = list(val_ds)\n",
    "test_list = list(test_ds)\n",
    "\n",
    "# Shuffle each list in-place\n",
    "random.shuffle(train_list)\n",
    "random.shuffle(val_list)\n",
    "random.shuffle(test_list)\n",
    "\n",
    "with open(os.path.join(output_dir, \"train_20p_prompt_variation.json\"), \"w\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(train_list, dest, ensure_ascii=False, default=str)\n",
    "\n",
    "with open(os.path.join(output_dir, \"validation_20p_prompt_variation.json\"), \"w\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(val_list, dest, ensure_ascii=False, default=str)\n",
    "\n",
    "with open(os.path.join(output_dir, \"test_prompt_variation.json\"), \"w\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(test_list, dest, ensure_ascii=False, default=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lZ_DFPLmpJ0",
    "outputId": "eea0b1e5-be9e-44ff-cfd6-9941ad572e34"
   },
   "outputs": [],
   "source": [
    "output_dir = os.path.join(data_dir, \"datasets\", \"llamafactory-finetune-data\")\n",
    "\n",
    "print(os.path.join(output_dir, \"train_20p_prompt_variation.json\"))\n",
    "print(os.path.join(output_dir, \"validation_20p_prompt_variation.json\"))\n",
    "print(os.path.join(output_dir, \"test_prompt_variation.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWuihGNrIsec"
   },
   "source": [
    "## Start Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6Oz6WIAIuGE",
    "outputId": "32431af6-f588-435c-c439-80b6728df21d"
   },
   "outputs": [],
   "source": [
    "# # Configure LLaMA-Factory for the new datasets\n",
    "\n",
    "# # update /content/LLaMA-Factory/data/dataset_info.json and append\n",
    "import json\n",
    "\n",
    "# Path to llama-factory dataset JSON file\n",
    "json_path = \"/content/LLaMA-Factory/data/dataset_info.json\"\n",
    "\n",
    "# New entries to add\n",
    "new_entries = {\n",
    "    \"authorship_styling_finetune_train\": {\n",
    "        \"file_name\": \"/gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/datasets/llamafactory-finetune-data/train_20p_prompt_variation.json\",\n",
    "        \"columns\": {\n",
    "            \"prompt\": \"instruction\",\n",
    "            \"query\": \"input\",\n",
    "            \"response\": \"output\",\n",
    "            \"system\": \"system\",\n",
    "            \"history\": \"history\"\n",
    "        }\n",
    "    },\n",
    "    \"authorship_styling_finetune_val\": {\n",
    "        \"file_name\": \"/gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/datasets/llamafactory-finetune-data/validation_20p_prompt_variation.json\",\n",
    "        \"columns\": {\n",
    "            \"prompt\": \"instruction\",\n",
    "            \"query\": \"input\",\n",
    "            \"response\": \"output\",\n",
    "            \"system\": \"system\",\n",
    "            \"history\": \"history\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 1: Load the current JSON data\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Step 2: Update the dictionary with new entries\n",
    "data.update(new_entries)\n",
    "\n",
    "# Step 3: Write the updated data back to the file\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(\"Datasets appended successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iXc4EPut_S4"
   },
   "outputs": [],
   "source": [
    "# metrics.py\n",
    "from evaluate import load\n",
    "\n",
    "bleu_metric  = load(\"bleu\")\n",
    "chrf_metric  = load(\"chrf\")\n",
    "model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "def compute_metrics_fn(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # decode\n",
    "    decoded_preds  = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # BLEU expects list of list-of-references\n",
    "    bleu_res = bleu_metric.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
    "    chrf_res = chrf_metric.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n",
    "    return {\n",
    "        \"bleu\": bleu_res[\"bleu\"],\n",
    "        \"charf\": chrf_res[\"score\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jX5pLadJI5tA",
    "outputId": "57c7dce1-197a-4c3d-80ec-96d941a3d595"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/LLaMA-Factory/examples/train_lora/authorship_style_transfer_finetune.yaml\n",
    "\n",
    "### model\n",
    "model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct\n",
    "# model_name_or_path: google/gemma-3-1b-it\n",
    "trust_remote_code: true\n",
    "\n",
    "### method\n",
    "stage: sft\n",
    "do_train: true\n",
    "finetuning_type: lora\n",
    "lora_rank: 32\n",
    "## default (lora_rank*2)\n",
    "lora_alpha: 64\n",
    "lora_dropout: 0.05\n",
    "##  rank-stabilized LoRA -> the update factor in RoLA becoma alpha/sqrt(r) instead of alpha/r\n",
    "# use_rslora: true\n",
    "##q_proj,k_proj,v_proj\n",
    "lora_target: all\n",
    "flash_attn: fa2\n",
    "## adding special token while fine-tuning maight cause vllm failed after training\n",
    "# add_special_tokens: <|task|>,<|author|>,<|source|>,<|output|>\n",
    "## Quantization method to use for on-the-fly, {bnb,gptq,awq,aqlm,quanto,eetq,hqq}, default bnb\n",
    "# quantization_method: awq\n",
    "## The number of bits to quantize the model using on-the-fly quantization {4, 8, 16}, default: none\n",
    "# quantization_bit: 4\n",
    "\n",
    "\n",
    "### dataset\n",
    "dataset: authorship_styling_finetune_train\n",
    "eval_dataset: authorship_styling_finetune_val\n",
    "template: qwen\n",
    "cutoff_len: 3500\n",
    "# max_samples: 50\n",
    "overwrite_cache: true\n",
    "preprocessing_num_workers: 16\n",
    "\n",
    "# <— enable generation & metrics\n",
    "# predict_with_generate: true\n",
    "# bleu is not supported by llama-factory ?!!\n",
    "metric_for_best_model: eval_loss\n",
    "# greater_is_better: true\n",
    "# compute_metrics: \"compute_metrics_fn\"   # point to your function\n",
    "# compute_accuracy: true\n",
    "### output\n",
    "# resume_from_checkpoint: /gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/llm-finetuning/models/checkpoint-2000\n",
    "output_dir: /gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/llm-finetuning/qwen-20p-lora32/\n",
    "logging_steps: 10\n",
    "save_steps: 500\n",
    "plot_loss: true\n",
    "log_level: error\n",
    "# overwrite_output_dir: true\n",
    "\n",
    "### train\n",
    "per_device_train_batch_size: 2\n",
    "gradient_accumulation_steps: 4\n",
    "learning_rate: 5.0e-6\n",
    "num_train_epochs: 3.0\n",
    "lr_scheduler_type: cosine\n",
    "warmup_ratio: 0\n",
    "bf16: true\n",
    "ddp_timeout: 180000000\n",
    "\n",
    "### eval\n",
    "# val_size: 0.1\n",
    "per_device_eval_batch_size: 2\n",
    "eval_strategy: steps\n",
    "eval_steps: 100\n",
    "eval_on_start: True\n",
    "# <— early stopping after N eval steps without improvement\n",
    "early_stopping_steps: 3     # stop if bleu doesn’t improve for n evals\n",
    "# load_best_model_at_end: true\n",
    "\n",
    "\n",
    "report_to: wandb\n",
    "run_name: authorship-style-transfer-finetune-llamafactory\n",
    "\n",
    "# push_to_hub: true\n",
    "export_hub_model_id: \"Tami3/authorship-style-transfer\"\n",
    "hub_private_repo: true\n",
    "hub_strategy: checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "PLT9UYfYtqMo",
    "outputId": "42306aeb-07f7-42ae-b17e-5a6891c41715"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo\n",
    "\n",
    "hf_username = !huggingface-cli whoami\n",
    "\n",
    "hf_username = hf_username[0]\n",
    "create_repo(f\"{hf_username}/authorship-style-transfer\", private=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cgs5fiVgHAKD"
   },
   "source": [
    "### Fine-tune model via LLaMA Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f__ysTWKHAtx"
   },
   "outputs": [],
   "source": [
    "%cd /content/LLaMA-Factory/\n",
    "!GRADIO_SHARE=1 llamafactory-cli webui\n",
    "\n",
    "# !cd LLaMA-Factory/ !GRADIO_SHARE=1 llamafactory-cli webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_exDWGCtaIq"
   },
   "outputs": [],
   "source": [
    "!cd /content/LLaMA-Factory/ && llamafactory-cli train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9vppN3IKCz9"
   },
   "outputs": [],
   "source": [
    "!cd /content/LLaMA-Factory/ && llamafactory-cli train /content/LLaMA-Factory/examples/train_lora/authorship_style_transfer_finetune.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izFrgLn45SWJ"
   },
   "source": [
    "## Fine-tuned Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ddu_D2O1OL2T"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "model_id = \"google/gemma-3-1b-it\"\n",
    "torch_dtype = \"auto\" # None, torch.float16\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "zx5jXc8I5Nr3",
    "outputId": "a47a4e77-1970-4a65-dc05-6bbc75e258f4"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype = torch_dtype\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLaZhMyz5V_s"
   },
   "outputs": [],
   "source": [
    "finetuned_model_id = \"/gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/llm-finetuning/gemma-12july-test-vllm\"\n",
    "model.load_adapter(finetuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vyhyKZFNVEKD",
    "outputId": "938639dc-6837-4787-e9a0-e788bcd96162"
   },
   "outputs": [],
   "source": [
    "idx = 400\n",
    "\n",
    "src_text = test_df.iloc[idx]['text_in_msa']\n",
    "transfered_text = test_df.iloc[idx]['text_in_author_style']\n",
    "author_name = test_df.iloc[idx]['author']\n",
    "\n",
    "print(f'{author_name=}')\n",
    "\n",
    "system_message = \"\\n\".join([\n",
    "    \"You are an advanced NLP experts specializing in text style transfer and semantic preservation.\",\n",
    "    \"Your role is to transform input text into the unique writing style of a specified author, ensuring the transformed output retains the original meaning, nuances, and intent.\",\n",
    "    \"Always follow instructions carefully, preserve the semantics of the source text, and ensure the generated output accurately reflects the distinctive style and tone of the given author.\",\n",
    "    \"Generate the ouptut in the same text language.\",\n",
    "    \"Do not generate any introduction or conclusion.\"\n",
    "])\n",
    "\n",
    "user_message = \"\\n\".join([\n",
    "            \"<task> Transform the following source text into the writing style of the specified author.\",\n",
    "            f\"<author> {author_name.strip()}\",\n",
    "            f\"<source> {src_text.strip()}\",\n",
    "            \"<output>\"\n",
    "        ])\n",
    "\n",
    "llm_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{'type': 'text', 'text': system_message}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{'type': 'text', 'text': user_message}]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpy0gEjQ5mf-",
    "outputId": "633364e8-c893-415a-ce63-abd60f49593c"
   },
   "outputs": [],
   "source": [
    "def generate_resp(messages):\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        max_new_tokens=3500,\n",
    "        do_sample=True, top_k=20, temperature=0.7, top_p=0.8,\n",
    "    )\n",
    "\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):]\n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response\n",
    "\n",
    "response = generate_resp(llm_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jdtSXgbT-Eu",
    "outputId": "756d8e2c-8f24-4664-c359-c925d9f0c3bc"
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shREjr-j5uH6"
   },
   "source": [
    "#### Tip for Qwen2.5\n",
    "\n",
    "Qwen2.5 oftenly produce chinese characters with some responses. To skip this, use the next class to generate responses.\n",
    "\n",
    "Source:\n",
    "`https://jupyter267.medium.com/how-to-eliminate-the-chance-of-generating-chinese-in-qwen-2-5-2cf919bb0fdc`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPgwXJC35xRr"
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, model, tokenizer):\n",
    "\n",
    "        self.model, self.tokenizer = model, tokenizer\n",
    "        self.mask = None\n",
    "\n",
    "    def generate(self, messages:list, max_new_tokens: int=2000, temperature:float=0.1):\n",
    "\n",
    "        def logits_processor(token_ids, logits):\n",
    "          # logits_processor default recieve the logits which is the score matrix of each time-step\n",
    "          \"\"\"\n",
    "              A processor to ban Chinese character\n",
    "          \"\"\"\n",
    "          if self.mask is None:\n",
    "              # as we don't know where the Chinses tokens locate at which index\n",
    "              # in the vocabulary but we know how it looks like and the range of it\n",
    "\n",
    "              # decode all the tokens in the vocabulary in order\n",
    "              token_ids = torch.arange(logits.size(-1))\n",
    "              decoded_tokens = self.tokenizer.batch_decode(token_ids.unsqueeze(1), skip_special_tokens=True)\n",
    "\n",
    "              # create a mask tensor to exclude positions of Chinese characters.\n",
    "              # since this process uses a for loop and is time-consuming,\n",
    "              # the result will be stored as a property for later use to ensure it only runs once.\n",
    "              self.mask = torch.tensor([\n",
    "                  # loop through each token in the vocabulary and compare it to Chinese characters.\n",
    "                  any(0x4E00 <= ord(c) <= 0x9FFF or 0x3400 <= ord(c) <= 0x4DBF or 0xF900 <= ord(c) <= 0xFAFF for c in\n",
    "                      token)\n",
    "                  for token in decoded_tokens\n",
    "              ])\n",
    "\n",
    "          # mask the score by - inf\n",
    "          logits[:, self.mask] = -float(\"inf\")\n",
    "          return logits\n",
    "\n",
    "        # this step transforms the messages into a string,\n",
    "        # adding special tokens e.g separate tokens between system content user queries\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            # add the logits_processor here\n",
    "            logits_processor=[logits_processor]\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4oah4hw54Zz"
   },
   "outputs": [],
   "source": [
    "# define an object\n",
    "llm = Generator(model, tokenizer)\n",
    "\n",
    "# generate a response without chinese characters\n",
    "response = llm.generate(details_extraction_messages)\n",
    "print( parse_json(response) )\n",
    "\n",
    "response = llm.generate(translation_messages)\n",
    "print( parse_json(response) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl2wEbzq6aVg"
   },
   "source": [
    "## vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZceNcf5p6cWP",
    "outputId": "51fde11b-c806-47fa-82ba-57130ec5f72c"
   },
   "outputs": [],
   "source": [
    "# base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "# base_model_id = \"google/gemma-3-1b-it\"\n",
    "# adapter_model_id = \"/gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/llm-finetuning/gemma-12july-test-vllm\"\n",
    "\n",
    "\n",
    "# !nohup vllm serve \"{base_model_id}\" --gpu-memory-utilization 0.8 --max_lora_rank 16 --enable-lora --lora-modules ast-lora=\"{adapter_model_id}\" &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_EHWeOKe6WX"
   },
   "source": [
    "vllm in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts0YXpjCeEA3"
   },
   "outputs": [],
   "source": [
    "vllm serve \"google/gemma-3-1b-it\" --dtype=half --gpu-memory-utilization 0.8 --max_lora_rank 32 --enable-lora --lora-modules ast-lora=\"/gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/llm-finetuning/gemma-20p-lora32/checkpoint-1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NV3N3sK-a3ym",
    "outputId": "cb1f2252-243c-4d60-89f2-f768ac42a2ed"
   },
   "outputs": [],
   "source": [
    "!tail -n 10 nohup.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pxTWvFy6tKH"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avOh7YLS6tkw"
   },
   "outputs": [],
   "source": [
    "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "base_model_id = \"google/gemma-3-1b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    llm_messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Dw_ZI416vv1",
    "outputId": "49d2e8ce-b774-4821-be79-c7748b93d04a"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "vllm_model_id = \"ast-lora\"\n",
    "\n",
    "llm_response = requests.post(\"http://localhost:8000/v1/completions\", json={\n",
    "    \"model\": vllm_model_id,\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 2000,\n",
    "    \"temperature\": 0.7\n",
    "})\n",
    "\n",
    "llm_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keJTH6dsyseU"
   },
   "source": [
    "batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxiU0qHh2Abm"
   },
   "outputs": [],
   "source": [
    "def construct_llm_messages(row):\n",
    "    author_name = row['author']\n",
    "    src_text = row['text_in_msa']\n",
    "\n",
    "    system_message = \"\\n\".join([\n",
    "        \"You are an advanced NLP experts specializing in text style transfer and semantic preservation.\",\n",
    "        \"Your role is to transform input text into the unique writing style of a specified author, ensuring the transformed output retains the original meaning, nuances, and intent.\",\n",
    "        \"Always follow instructions carefully, preserve the semantics of the source text, and ensure the generated output accurately reflects the distinctive style and tone of the given author.\",\n",
    "        \"Generate the ouptut in the same text language.\",\n",
    "        \"Do not generate any introduction or conclusion.\"\n",
    "    ])\n",
    "\n",
    "    user_message = \"\\n\".join([\n",
    "        \"<task> Transform the following source text into the writing style of the specified author.\",\n",
    "        f\"<author> {author_name.strip()}\",\n",
    "        f\"<source> {src_text.strip()}\",\n",
    "        \"<output>\"\n",
    "    ])\n",
    "\n",
    "    llm_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{'type': 'text', 'text': system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{'type': 'text', 'text': user_message}]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return llm_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bk51I7kC8iDa"
   },
   "outputs": [],
   "source": [
    "# df2 = test_df.sample(n=100)\n",
    "df2 = pd.read_csv(\"/gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/datasets/llamafactory-finetune-data/predictions_100s.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "cLcCtoVCyuGX",
    "outputId": "127943b8-f374-42cd-bb0c-4965646c4c41"
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "def process_row(row, tokenizer, model_id=\"ast-lora\"):\n",
    "    # 1. Construct llm_messages\n",
    "    llm_messages = construct_llm_messages(row)\n",
    "    # 2. Build prompt\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        llm_messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    # 3. Call API\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://localhost:8000/v1/completions\",\n",
    "            json={\n",
    "                \"model\": model_id,\n",
    "                \"prompt\": prompt,\n",
    "                \"max_tokens\": 2000,\n",
    "                \"temperature\": 0.7\n",
    "            },\n",
    "            timeout=30\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get(\"choices\", [{}])[0].get(\"text\", \"\")\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            return f\"Error: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {str(e)}\")\n",
    "        return f\"Exception: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "def batch_process(df, tokenizer, model_id=\"ast-lora\"):\n",
    "    responses = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
    "        try:\n",
    "            response = process_row(row, tokenizer, model_id)\n",
    "            responses.append(response)\n",
    "        except Exception as exc:\n",
    "            responses.append(f\"Exception: {str(exc)}\")\n",
    "    return responses\n",
    "\n",
    "# Usage\n",
    "test_df['gemma_lora32_response'] = batch_process(test_df, tokenizer, model_id=\"ast-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQDz41-zSiFS"
   },
   "outputs": [],
   "source": [
    "data_dir = \"/gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/datasets/llamafactory-finetune-data/testset_predictions.csv\"\n",
    "test_df.to_csv(data_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXDdrYs5oQPI",
    "outputId": "89b35738-2b58-45b5-8ab3-60986fe35e1f"
   },
   "outputs": [],
   "source": [
    "!pip install -q sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjYUFVv9oOBc",
    "outputId": "fa478e85-b01d-4bfb-d387-49c3ac2ead1c"
   },
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "\n",
    "import sacrebleu\n",
    "\n",
    "# Prepare lists of hypotheses and references\n",
    "gemma32_preds = test_df['gemma_rslora64'].tolist()\n",
    "# gemma32_preds = df2['gemma_lora32'].tolist()\n",
    "# gemma16_preds = df2['gemma_lora16'].tolist()\n",
    "# qwen16_preds = df2['qwen_llm_response'].tolist()\n",
    "\n",
    "refs = test_df['text_in_author_style'].tolist()\n",
    "\n",
    "# sacrebleu expects a list of references (for multi-ref support), so wrap refs in a list\n",
    "gemma32_bleu = sacrebleu.corpus_bleu(gemma32_preds, [refs])\n",
    "gemma32_chrf = sacrebleu.corpus_chrf(gemma32_preds, [refs])\n",
    "\n",
    "# gemma32_bleu = sacrebleu.corpus_bleu(gemma32_preds, [refs])\n",
    "# gemma32_chrf = sacrebleu.corpus_chrf(gemma32_preds, [refs])\n",
    "\n",
    "# gemma16_bleu = sacrebleu.corpus_bleu(gemma16_preds, [refs])\n",
    "# gemma16_chrf = sacrebleu.corpus_chrf(gemma16_preds, [refs])\n",
    "\n",
    "# qwen16_bleu = sacrebleu.corpus_bleu(qwen16_preds, [refs])\n",
    "# qwen16_chrf = sacrebleu.corpus_chrf(qwen16_preds, [refs])\n",
    "\n",
    "print(f\"{gemma32_bleu.score=:.2f}\")\n",
    "\n",
    "print(f\"{gemma32_chrf.score=:.2f}\")\n",
    "# print(\"BLEU details:\", bleu)\n",
    "# print(\"chrF details:\", chrf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjwuFVn02v65"
   },
   "source": [
    "merge and deploy to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZv3iiql38nk",
    "outputId": "0f1d748a-5ef3-4bed-fa80-b7fa5dd2dab5"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/LLaMA-Factory/examples/merge_lora/authorship_style_transfer_finetune.yaml\n",
    "\n",
    "### model\n",
    "\n",
    "model_name_or_path: google/gemma-3-1b-it\n",
    "adapter_name_or_path: /gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/llm-finetuning/gemma-20p-lora32/checkpoint-1000\n",
    "template: gemma2\n",
    "trust_remote_code: true\n",
    "\n",
    "# LoRA fine-tuning type\n",
    "finetuning_type: lora\n",
    "stage: sft\n",
    "\n",
    "### export\n",
    "export_dir: /gdrive/MyDrive/AraGenEval shared task/AuthorshipStyleTransferTask1/llm-finetuning/gemma-20p-lora32/merged\n",
    "export_size: 5\n",
    "export_device: auto  # choices: [cpu, auto]\n",
    "export_legacy_format: false\n",
    "\n",
    "# push_to_hub: true\n",
    "export_hub_model_id: \"Tami3/authorship-style-transfer\"\n",
    "# hub_private_repo: true\n",
    "# hub_strategy: checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GiT8yyB1FxC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnCfzXXs1APX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44-XS04c2xuy",
    "outputId": "06a4acb7-84df-4318-f1fe-0f7dd86fff3b"
   },
   "outputs": [],
   "source": [
    "!cd /content/LLaMA-Factory/ && llamafactory-cli export /content/LLaMA-Factory/examples/merge_lora/authorship_style_transfer_finetune.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31d4c617"
   },
   "outputs": [],
   "source": [
    "# Uninstall the current transformers version\n",
    "!pip uninstall -y transformers\n",
    "\n",
    "# Install a specific version that should support Qwen 2.5\n",
    "# You might need to adjust the version number based on the latest releases\n",
    "# and compatibility with other libraries you are using (like LLaMA-Factory)\n",
    "!pip install -qU transformers>=4.40.0\n",
    "\n",
    "# Re-run the cell with the error after this installation"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QqIRbR8Ivnks",
    "shREjr-j5uH6"
   ],
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03041a6825bb4bfb921a4c853c03ed64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "192a977575b1422f911dd1e1e387bdaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c24e6c23780242399239fadf3e13d4f8",
      "placeholder": "​",
      "style": "IPY_MODEL_60072b5e25324f27a29b955ce35c942b",
      "value": "100%"
     }
    },
    "1dc7587750974e8e8f9595868ad783df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e62a90af4ab4155a5766a3e073edc71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e923f93705e4d98ae2f743db3228409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8640e77d0f304f089f13c9d651e38f68",
       "IPY_MODEL_85d6c0a1db154bd99f12dcee540cdd35",
       "IPY_MODEL_43689df49f6a4de0a3264be460ca102a"
      ],
      "layout": "IPY_MODEL_6caafade35644e0993d7de1c609d58a0"
     }
    },
    "1fac024aec2c41d1810808424aaa9fc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fbc02059b3f43918ca1f49d3ff22b5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0ca7e6b70734a69934c4cc62a49a57f",
      "placeholder": "​",
      "style": "IPY_MODEL_c3dca4902301494f836f85939ab2b9c0",
      "value": " 4157/4157 [00:00&lt;00:00, 63762.94it/s]"
     }
    },
    "21cdcfb3187b445193835c3828cf8d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_553b3334a1124074a44e23172011a20d",
      "placeholder": "​",
      "style": "IPY_MODEL_4d283dfc38874eb5a071d0956aba6d10",
      "value": " 9/9 [00:01&lt;00:00,  5.15it/s]"
     }
    },
    "23ce5043154c4af5a6a9102bf476e4ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ccb2a0c4bee409db646b2252b091f8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32bcb568e8dc4c4f9158e218ec6e99e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a337862d48d4d18923189342dbfa724": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bd9d0bbfc1c4038a14730b05fec755c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9360c990d2d8410e9324736298bf835a",
      "max": 4157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6661a836a06f4029a09a9dd2e27396d9",
      "value": 4157
     }
    },
    "3bdf5602c3c448d489fcb2b9e964278d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_657506d1799e437c885a4a8420f3573b",
      "placeholder": "​",
      "style": "IPY_MODEL_82408f3e12fe48de8ac882c6edb7aae2",
      "value": "100%"
     }
    },
    "40b4746daf004b4ca3faac5fda98c66e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43689df49f6a4de0a3264be460ca102a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a337862d48d4d18923189342dbfa724",
      "placeholder": "​",
      "style": "IPY_MODEL_c24e21cdfc274ac79e0666c08ce36f98",
      "value": " 703/703 [00:00&lt;00:00, 37432.03it/s]"
     }
    },
    "49f2ca1f719c432b98d55acfdd0c8502": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d283dfc38874eb5a071d0956aba6d10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4eac538908554978b24ef03ade0bbb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50b4d877c55d4506b9d45084ca459067": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "553b3334a1124074a44e23172011a20d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bf8a703640649029f7a9349c0a456fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f5f130179054ccd8c0971fe0c4ccf21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23ce5043154c4af5a6a9102bf476e4ba",
      "max": 6321,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49f2ca1f719c432b98d55acfdd0c8502",
      "value": 6321
     }
    },
    "60072b5e25324f27a29b955ce35c942b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61f74c31f9414c2d97e331cc3bc9c395": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "625e31c6fd074b8bb3e55b29503bc784": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "657506d1799e437c885a4a8420f3573b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6661a836a06f4029a09a9dd2e27396d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69d1dfa44d10419f84bbf6215e3b6b6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95372ecbe05a4662839a5aa8785c64c7",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb862ae335b74fcd823e3b84066adb03",
      "value": 9
     }
    },
    "6caafade35644e0993d7de1c609d58a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7afcd5353ac24a07b973154a93a0c6aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b427d66ca6f4f8b88ef507d89993960": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e77fb1f187c4b0b906d07bcc7ae4487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_192a977575b1422f911dd1e1e387bdaa",
       "IPY_MODEL_69d1dfa44d10419f84bbf6215e3b6b6d",
       "IPY_MODEL_21cdcfb3187b445193835c3828cf8d21"
      ],
      "layout": "IPY_MODEL_40b4746daf004b4ca3faac5fda98c66e"
     }
    },
    "82408f3e12fe48de8ac882c6edb7aae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85d6c0a1db154bd99f12dcee540cdd35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50b4d877c55d4506b9d45084ca459067",
      "max": 703,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ffad0664c3a340a59a4eec2385361605",
      "value": 703
     }
    },
    "8640e77d0f304f089f13c9d651e38f68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4eac538908554978b24ef03ade0bbb9f",
      "placeholder": "​",
      "style": "IPY_MODEL_1e62a90af4ab4155a5766a3e073edc71",
      "value": "100%"
     }
    },
    "8eae1c26c173488ea4eee86ec694e76a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b94cc3628be84ac4a6475fca0cfd65d1",
      "placeholder": "​",
      "style": "IPY_MODEL_9eea68c350de4d3a9949670e4f93fefd",
      "value": "100%"
     }
    },
    "9360c990d2d8410e9324736298bf835a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95372ecbe05a4662839a5aa8785c64c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eea68c350de4d3a9949670e4f93fefd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0e1bcc9f26d4a658e9b759898401e1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8eae1c26c173488ea4eee86ec694e76a",
       "IPY_MODEL_3bd9d0bbfc1c4038a14730b05fec755c",
       "IPY_MODEL_1fbc02059b3f43918ca1f49d3ff22b5a"
      ],
      "layout": "IPY_MODEL_2ccb2a0c4bee409db646b2252b091f8d"
     }
    },
    "b0ca7e6b70734a69934c4cc62a49a57f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b84c34772a8247ce9ec7f0d07854f186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9a1149023b34161837f6256e29c87bd",
      "placeholder": "​",
      "style": "IPY_MODEL_32bcb568e8dc4c4f9158e218ec6e99e9",
      "value": "100%"
     }
    },
    "b94cc3628be84ac4a6475fca0cfd65d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c24e21cdfc274ac79e0666c08ce36f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c24e6c23780242399239fadf3e13d4f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3dca4902301494f836f85939ab2b9c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce9e406574ef4ac88cb52d207f4f38e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3bdf5602c3c448d489fcb2b9e964278d",
       "IPY_MODEL_5f5f130179054ccd8c0971fe0c4ccf21",
       "IPY_MODEL_e2c28a0a494940e7931e33556bd85ad3"
      ],
      "layout": "IPY_MODEL_625e31c6fd074b8bb3e55b29503bc784"
     }
    },
    "d187ae3b428f4130a11ea157183b5b98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7afcd5353ac24a07b973154a93a0c6aa",
      "placeholder": "​",
      "style": "IPY_MODEL_7b427d66ca6f4f8b88ef507d89993960",
      "value": " 69/69 [00:15&lt;00:00,  4.83it/s]"
     }
    },
    "d9c28ca7d5b14b76b6a7a35d3cd76a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61f74c31f9414c2d97e331cc3bc9c395",
      "max": 69,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1dc7587750974e8e8f9595868ad783df",
      "value": 69
     }
    },
    "e2c28a0a494940e7931e33556bd85ad3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03041a6825bb4bfb921a4c853c03ed64",
      "placeholder": "​",
      "style": "IPY_MODEL_5bf8a703640649029f7a9349c0a456fb",
      "value": " 6321/6321 [00:00&lt;00:00, 39802.26it/s]"
     }
    },
    "e8c7543fdf6345f4bfd1088c827dbffc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b84c34772a8247ce9ec7f0d07854f186",
       "IPY_MODEL_d9c28ca7d5b14b76b6a7a35d3cd76a65",
       "IPY_MODEL_d187ae3b428f4130a11ea157183b5b98"
      ],
      "layout": "IPY_MODEL_1fac024aec2c41d1810808424aaa9fc3"
     }
    },
    "e9a1149023b34161837f6256e29c87bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb862ae335b74fcd823e3b84066adb03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ffad0664c3a340a59a4eec2385361605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
